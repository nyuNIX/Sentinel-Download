{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyuNIX/Sentinel-Download/blob/main/Sentinel2_Talhoes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para rodar essa parte tem-se que fazer a conexão de modo interativa com o drive.\n",
        "\n",
        "O mesmo se aplica ao projeto do GEE da sua conta (já abilitado a conexão com o sentinel-2)"
      ],
      "metadata": {
        "id": "hPyKgKupqBlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNLQOvCMLaey"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "#  - Monta o Google Drive\n",
        "#  - Instala dependências geoespaciais (necessárias apenas para SHP)\n",
        "#  - Autentica e inicializa o Google Earth Engine\n",
        "# =============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dependências necessárias apenas se forem usados shapefiles (.shp ou .zip).\n",
        "# GeoJSON puro não exige geopandas, mas manter aqui evita erros futuros.\n",
        "!pip install --quiet geopandas fiona shapely pyproj rtree\n",
        "\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import tempfile\n",
        "import ee\n",
        "\n",
        "# Autenticação interativa do Earth Engine (modo usuário)\n",
        "ee.Authenticate()   # abrirá um link e solicitará o token\n",
        "ee.Initialize(project='sentinel-479818')\n",
        "\n",
        "print(\"Drive montado e Earth Engine inicializado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cloudProbThreshold e maxAllowedCloudPercentage são valores que podem ser alterados conforme a necessidade. Dependem do modelo e do que buscamos inferir  "
      ],
      "metadata": {
        "id": "gx_u5s-M-aim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intervalo temporal de busca das imagens Sentinel-2\n",
        "start_Date = '2024-01-01'\n",
        "end_Date   = '2024-01-10'\n",
        "\n",
        "# Threshold (%) de probabilidade de nuvem (S2 Cloud Probability)\n",
        "# Pixels acima desse valor são considerados nuvem\n",
        "cloudProbThreshold = 50\n",
        "\n",
        "# Porcentagem (%) de nuvem aceitavel dentro do talhão\n",
        "# Se dentro do talhão tiver um valor maior ou igual a X% ele ainda é coletado\n",
        "maxAllowedCloudPercentage = 0.1  # 10%\n",
        "\n",
        "# Bandas a serem exportadas (RGB)\n",
        "bands = ['B2', 'B3', 'B4']\n",
        "\n",
        "# Limite máximo de pixels permitido por export (Earth Engine safeguard)\n",
        "maxPixels = 1e13\n",
        "\n",
        "# Diretório no Google Drive contendo os polígonos de entrada\n",
        "talhoes_dir = '/content/drive/MyDrive/GEE_EXPORT/Talhoes'\n",
        "\n",
        "# Pasta base de saída no Google Drive\n",
        "# Subpastas serão criadas automaticamente para cada polígono\n",
        "drive_export_folder = 'Dataset-output'\n",
        "base_output_path = f\"/content/drive/MyDrive/GEE_EXPORT/{drive_export_folder}\"\n",
        "\n",
        "print(\"Configurações carregadas.\")\n",
        "print(\"Procurando polígonos em:\", talhoes_dir)\n"
      ],
      "metadata": {
        "id": "QItKWWDsMZ88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "def load_fc_from_shp(shp_path):\n",
        "    \"\"\"\n",
        "    Lê um shapefile local e o converte para ee.FeatureCollection.\n",
        "    Caso o CRS não seja EPSG:4326, a reprojeção é aplicada.\n",
        "    \"\"\"\n",
        "    gdf = gpd.read_file(shp_path)\n",
        "    if gdf.crs and gdf.crs.to_string() != 'EPSG:4326':\n",
        "        gdf = gdf.to_crs(epsg=4326)\n",
        "    return ee.FeatureCollection(json.loads(gdf.to_json()))\n",
        "\n",
        "\n",
        "def load_all_polygons_from_drive_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Varre uma pasta do Google Drive e carrega todos os polígonos encontrados,\n",
        "    suportando os seguintes formatos:\n",
        "      1) GeoJSON / JSON\n",
        "      2) Shapefiles soltos (.shp)\n",
        "      3) Shapefiles compactados (.zip)\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    list of tuples\n",
        "        Lista de pares (nome_base, ee.FeatureCollection)\n",
        "    \"\"\"\n",
        "    items = []\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        raise FileNotFoundError(\"Pasta não encontrada: \" + folder_path)\n",
        "\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1) GeoJSON / JSON\n",
        "    # -------------------------------------------------------------------------\n",
        "    for f in files:\n",
        "        if f.lower().endswith(('.geojson', '.json')):\n",
        "            name = os.path.splitext(f)[0]\n",
        "            path = os.path.join(folder_path, f)\n",
        "            with open(path, 'r', encoding='utf-8') as fp:\n",
        "                gj = json.load(fp)\n",
        "            items.append((name, ee.FeatureCollection(gj)))\n",
        "            print(\"Carregado GeoJSON:\", f)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 2) Shapefiles soltos (.shp)\n",
        "    # -------------------------------------------------------------------------\n",
        "    shp_files = [f for f in files if f.lower().endswith('.shp')]\n",
        "    for shp in shp_files:\n",
        "        name = os.path.splitext(shp)[0]\n",
        "        shp_path = os.path.join(folder_path, shp)\n",
        "        try:\n",
        "            fc = load_fc_from_shp(shp_path)\n",
        "            items.append((name, fc))\n",
        "            print(\"Carregado SHP:\", shp)\n",
        "        except Exception as e:\n",
        "            print(\"Erro ao carregar SHP\", shp, \"->\", e)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3) Shapefiles compactados (.zip)\n",
        "    # -------------------------------------------------------------------------\n",
        "    for f in files:\n",
        "        if f.lower().endswith('.zip'):\n",
        "            name = os.path.splitext(f)[0]\n",
        "            zip_path = os.path.join(folder_path, f)\n",
        "            try:\n",
        "                with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "                    tmpdir = tempfile.mkdtemp()\n",
        "                    z.extractall(tmpdir)\n",
        "\n",
        "                shp_inside = [\n",
        "                    os.path.join(tmpdir, x)\n",
        "                    for x in os.listdir(tmpdir)\n",
        "                    if x.lower().endswith('.shp')\n",
        "                ]\n",
        "\n",
        "                if shp_inside:\n",
        "                    fc = load_fc_from_shp(shp_inside[0])\n",
        "                    items.append((name, fc))\n",
        "                    print(\"Carregado SHP ZIP:\", f)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(\"Erro ao carregar ZIP\", f, \"->\", e)\n",
        "\n",
        "    return items\n",
        "\n",
        "\n",
        "# Execução do carregamento\n",
        "polygons_list = load_all_polygons_from_drive_folder(talhoes_dir)\n",
        "print(\"Total de FeatureCollections carregadas:\", len(polygons_list))\n"
      ],
      "metadata": {
        "id": "Vvmd8MZANckt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste processamento, todas as imagens Sentinel-2 que intersectam a geometria de interesse são mantidas, mesmo quando pertencem à mesma data de aquisição. Isso ocorre porque o Sentinel-2 é organizado em tiles MGRS independentes, e um mesmo polígono pode estar localizado na sobreposição de múltiplos tiles. Nesses casos, produtos adquiridos no mesmo instante podem apresentar condições distintas de cobertura de nuvens sobre a área de interesse, de modo que descartar imagens apenas com base na data poderia resultar na perda de informação válida. A manutenção de todos os produtos introduz uma **redundância positiva**, aumentando a robustez do conjunto de dados e reduzindo lacunas causadas por nuvens."
      ],
      "metadata": {
        "id": "VNO2_Dh_5sek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cloud_probability_join(s2_col, cloud_col):\n",
        "    \"\"\"\n",
        "    Associa a cada imagem Sentinel-2 SR a respectiva imagem de\n",
        "    probabilidade de nuvem (S2Cloudless) utilizando um join exato\n",
        "    baseado na propriedade 'system:index'.\n",
        "\n",
        "    Esta é a abordagem oficialmente recomendada pelo Google Earth Engine.\n",
        "\n",
        "    https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless\n",
        "    \"\"\"\n",
        "\n",
        "    joined = ee.Join.saveFirst('cloud_prob_img').apply(\n",
        "        primary=s2_col,\n",
        "        secondary=cloud_col,\n",
        "        condition=ee.Filter.equals(\n",
        "            leftField='system:index',\n",
        "            rightField='system:index'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    def _append_cloud_band(img):\n",
        "        cloud_img = ee.Image(img.get('cloud_prob_img'))\n",
        "\n",
        "        # Proteção defensiva (caso raro de imagem sem par)\n",
        "        cloud_prob = ee.Algorithms.If(\n",
        "            cloud_img,\n",
        "            cloud_img.select('probability').rename('cloud_prob'),\n",
        "            ee.Image.constant(0).rename('cloud_prob')\n",
        "        )\n",
        "\n",
        "        return ee.Image(img).addBands(ee.Image(cloud_prob))\n",
        "\n",
        "    return ee.ImageCollection(joined).map(_append_cloud_band)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_polygon_fc(name, fc, startDate, endDate, drive_subfolder):\n",
        "    \"\"\"\n",
        "    Processa um ee.FeatureCollection contendo um ou mais polígonos.\n",
        "    Cada feição é tratada como um talhão independente, realizando:\n",
        "      - busca de imagens Sentinel-2\n",
        "      - associação com probabilidade de nuvem (S2Cloudless)\n",
        "      - filtragem de imagens sem nuvem sobre o polígono\n",
        "      - exportação das imagens limpas para o Google Drive\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "    name : str\n",
        "        Nome base do arquivo de entrada (usado para identificar os talhões).\n",
        "    fc : ee.FeatureCollection\n",
        "        Coleção de feições (talhões).\n",
        "    startDate : str\n",
        "        Data inicial da busca de imagens Sentinel-2.\n",
        "    endDate : str\n",
        "        Data final da busca de imagens Sentinel-2.\n",
        "    drive_subfolder : str\n",
        "        Subpasta no Google Drive onde os exports serão salvos.\n",
        "    \"\"\"\n",
        "\n",
        "    # Conversão controlada para client-side apenas para iterar feições\n",
        "    features = fc.getInfo().get('features', [])\n",
        "    if not features:\n",
        "        print(\"Nenhuma feição no FeatureCollection:\", name)\n",
        "        return\n",
        "\n",
        "    for idx, feat in enumerate(features):\n",
        "        geom = ee.Geometry(feat['geometry'])\n",
        "        talhao_name = f\"{name}_f{idx}\"\n",
        "\n",
        "        print(\"Processando talhão:\", talhao_name)\n",
        "\n",
        "        s2 = (\n",
        "            ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "            .filterBounds(geom)\n",
        "            .filterDate(startDate, endDate)\n",
        "            .sort('system:time_start')\n",
        "        )\n",
        "\n",
        "        cloudProbCol = (\n",
        "            ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "            .filterBounds(geom)\n",
        "            .filterDate(startDate, endDate)\n",
        "        )\n",
        "\n",
        "        withCloud = add_cloud_probability_join(s2, cloudProbCol)\n",
        "\n",
        "        # ---------------------------------------------------------------------\n",
        "        # Avaliação de presença de nuvem sobre o polígono\n",
        "        # Estratégia: reduceRegion(max) sobre máscara de nuvem\n",
        "        # ---------------------------------------------------------------------\n",
        "        def annotate_fn(img):\n",
        "            cloudMask = img.select('cloud_prob').gt(cloudProbThreshold)\n",
        "\n",
        "            # Conta pixels com nuvem\n",
        "            cloud_pixels = cloudMask.reduceRegion(\n",
        "                reducer=ee.Reducer.sum(),\n",
        "                geometry=geom,\n",
        "                scale=10,\n",
        "                maxPixels=maxPixels\n",
        "            ).values().get(0)\n",
        "\n",
        "            # Conta pixels válidos no polígono\n",
        "            total_pixels = cloudMask.reduceRegion(\n",
        "                reducer=ee.Reducer.count(),\n",
        "                geometry=geom,\n",
        "                scale=10,\n",
        "                maxPixels=maxPixels\n",
        "            ).values().get(0)\n",
        "\n",
        "            # Percentual de nuvem\n",
        "            cloud_fraction = ee.Number(cloud_pixels).divide(ee.Number(total_pixels))\n",
        "\n",
        "            # Limite de tolerância\n",
        "            cloud_free = cloud_fraction.lte(maxAllowedCloudPercentage)\n",
        "\n",
        "            return img.set({\n",
        "                'cloud_fraction': cloud_fraction,\n",
        "                'cloud_free': cloud_free\n",
        "            })\n",
        "\n",
        "        annotated = withCloud.map(annotate_fn)\n",
        "\n",
        "        # Mantém apenas imagens completamente livres de nuvem\n",
        "        clean = annotated.filter(ee.Filter.eq('cloud_free', 1))\n",
        "\n",
        "\n",
        "\n",
        "        # try:\n",
        "        #     total_count = s2.size().getInfo()\n",
        "        #     clean_count = clean.size().getInfo()\n",
        "        # except Exception:\n",
        "        #     total_count, clean_count = 'N/A', 'N/A'\n",
        "\n",
        "        # print(f\"Talhão {talhao_name} -> total scenes: {total_count}, clean scenes: {clean_count}\")\n",
        "\n",
        "        try:\n",
        "            ids = clean.aggregate_array('system:index').getInfo()\n",
        "        except Exception:\n",
        "            ids = []\n",
        "\n",
        "        if not ids:\n",
        "            print(\"Nenhuma imagem limpa para:\", talhao_name)\n",
        "            continue\n",
        "\n",
        "        print(f\"Criando exports para {talhao_name} -> {len(ids)} imagens\")\n",
        "\n",
        "\n",
        "        for img_idx in ids:\n",
        "            img = ee.Image(clean.filter(ee.Filter.eq('system:index', img_idx)).first())\n",
        "\n",
        "\n",
        "            img_id = img.get('system:index').getInfo()\n",
        "            export_name = f\"sentinel_{talhao_name}_{img_id}\"\n",
        "\n",
        "\n",
        "            try:\n",
        "                bounds_info = geom.bounds().getInfo()\n",
        "                region = bounds_info['coordinates']\n",
        "            except Exception:\n",
        "                region = geom.centroid().getInfo().get('coordinates')\n",
        "\n",
        "            task = ee.batch.Export.image.toDrive(\n",
        "                image=img.select(bands).clip(geom), # recorte preciso\n",
        "                description=export_name,\n",
        "                folder=drive_subfolder,\n",
        "                fileNamePrefix=export_name,\n",
        "                region=region,\n",
        "                scale=10,\n",
        "                maxPixels=int(maxPixels)\n",
        "            )\n",
        "            task.start()\n",
        "            print(\"Export task iniciada:\", export_name)\n",
        "\n",
        "    print(\"Processamento do arquivo\", name, \"concluído.\")\n"
      ],
      "metadata": {
        "id": "P-j7SsBTNgh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not polygons_list:\n",
        "    print(\"Nenhum arquivo de polígonos encontrado em\", talhoes_dir)\n",
        "else:\n",
        "    for name, fc in polygons_list:\n",
        "        try:\n",
        "\n",
        "            # cria pasta específica do polígono\n",
        "            polygon_output_path = os.path.join(base_output_path, name)\n",
        "            os.makedirs(polygon_output_path, exist_ok=True)\n",
        "\n",
        "            process_polygon_fc(name, fc, start_Date, end_Date, drive_subfolder=name)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Erro ao processar\", name, \"->\", e)\n",
        "\n",
        "print(\"Todas as tasks foram criadas (verifique o painel Tasks no Earth Engine).\")\n",
        "\n",
        "#https://code.earthengine.google.com/tasks\n"
      ],
      "metadata": {
        "id": "rn0Lg72TNinJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}